{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":23186829,"authorName":"Paul Prescod","from":"Paul Prescod &lt;paul@...&gt;","profile":"papresco","replyTo":"SENDER","senderId":"k71yD4oO_DyiHQT7Hylz7KHRo-ODc7xMCdjX6hkXiyNX_0H1yN2WVS7eq5gzQObZBNCjGwGtJYdhj9agOBeY4EGDlxcjoA","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Rediscovering Web Architecture  from first principles","postDate":"1031853984","msgId":2540,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDNEODBEN0EwLjcwMTAwMDBAcHJlc2NvZC5uZXQ+"},"prevInTopic":0,"nextInTopic":2542,"prevInTime":2539,"nextInTime":2541,"topicId":2540,"numMessagesInTopic":7,"msgSnippet":"= Addressing = The Web is first and foremost a publishing platform. It is used to publish information and services. We will start with the question of the best","rawEmail":"Return-Path: &lt;paul@...&gt;\r\nX-Sender: paul@...\r\nX-Apparently-To: rest-discuss@yahoogroups.com\r\nReceived: (EGP: mail-8_1_1_3); 13 Sep 2002 19:22:39 -0000\r\nReceived: (qmail 44994 invoked from network); 13 Sep 2002 19:22:39 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m6.grp.scd.yahoo.com with QMQP; 13 Sep 2002 19:22:39 -0000\r\nReceived: from unknown (HELO smtp1.ActiveState.com) (209.17.183.249)\n  by mta1.grp.scd.yahoo.com with SMTP; 13 Sep 2002 19:22:39 -0000\r\nReceived: from smtp3.ActiveState.com (smtp3.ActiveState.com [192.168.3.19])\n\tby smtp1.ActiveState.com (8.11.6/8.11.6) with ESMTP id g8DJMbj12049\n\tfor &lt;rest-discuss@yahoogroups.com&gt;; Fri, 13 Sep 2002 12:22:38 -0700\r\nReceived: from prescod.net (ssh1.ActiveState.com [192.168.3.32])\n\tby smtp3.ActiveState.com (8.11.6/8.11.6) with ESMTP id g8DJMbi00673\n\tfor &lt;rest-discuss@yahoogroups.com&gt;; Fri, 13 Sep 2002 12:22:37 -0700\r\nMessage-ID: &lt;3D80D7A0.7010000@...&gt;\r\nDate: Thu, 12 Sep 2002 11:06:24 -0700\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; PPC Mac OS X; en-US; rv:1.1) Gecko/20020826\r\nX-Accept-Language: en-us, en\r\nMIME-Version: 1.0\r\nTo: rest-discuss@yahoogroups.com\r\nSubject: Rediscovering Web Architecture  from first principles\r\nContent-Type: text/plain; charset=us-ascii; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-Filtered-By: PerlMx makes it fast and easy.  See http://www.ActiveState.com/Products/PerlMx/Header\r\nFrom: Paul Prescod &lt;paul@...&gt;\r\nX-Yahoo-Group-Post: member; u=23186829\r\nX-Yahoo-Profile: papresco\r\n\r\n    = Addressing =\n\nThe Web is first and foremost a publishing platform. It is used to\npublish information and services.\n\nWe will start with the question of the best way to publish information.\nThere are two basic strategies possible: one is to describe uniquely for\neach information object how to fetch it. Another is to standardize the\nfetching mechanism and instead specify only the minimal information\nrequired to actually do the fetch: an &quot;address&quot;.\n\nThe older FTP protocol uses the first model. When you wanted someone to \ndownload something through FTP you would give them instructions about \nhow to log into an FTP site, switch to the appropriate directory and get \nthe appropriate file. Conversely, HTTP leaves only one free parameter: \nthe address. Everything else falls out of that. You do not need to \nchoose the method that is used: it is always GET. You do not need to \ndecide what server to issue the command to: the address of the \nrecommended server is embedded in the address (&quot;Uniform Resource \nidentifier&quot;, or &quot;URI&quot;).\n\nThis leads us to the Web principle that all resources should be\nidentifiable by unique address so that they can be fetched with only GET \nand the address.\n\n    = Uniform Interface =\n\nStandardizing the means of information download is important for\nmaximizing the number of applications that can download information\nwithout necessarily understanding the semantics of the information they\nare downloading. Examples include caching and prefetching\nproxies, command line downloading tools, web browsers, spiders and XSLT\nengines.\n\nAny architecture that has multiple ways of saying &quot;get me some\ninformation&quot; will experience interoperability problems that the Web\navoids by having a few, globally optimized ways of doing so (basically\nHTTP and FTP GET methods).\n\nBecause HTTP&#39;s GET is used by such a wide variety of tools, it is\nnecessary that it have very clear semantics. For instance, a GET cannot\nbe interpreted as signing a user up for a service or a prefetching cache\nor spider could sign the user up just by doing its job. Therefore the\nWeb says that end-users are not responsible for any side effects of GET.\n    Services should not use GET in ways that cause side effects.\n\nLet me stress a point made earlier: any architecture that allows every\nend-node to choose its own mechanism for delivering information (SOAP\nRPC, CORBA, ...) is strictly less powerful and less interoperable than\nan architecture that has a single, standardized way to deliver\ninformation because it means that every potential consumer of\ninformation resources must be customized to talk to every publisher of\ninformation. This is an interoperability nightmare.\n\nThe concensus on this point is sufficiently strong that the W3C has\nextended SOAP 1.2 to support HTTP GET so that it would better take\nadvantage of the features of web architecture.\n\n    = Hypermedia =\n\nBut simply returning named information is not always enough. Often the\nclient application or human web surfer will not know exactly what\ninformation they need in advance. Essentially they need to be given a\nmenu of options so that they may choose the appropriate one. For\ninstance a flight-purchasing agent might be presented with a list of\nflights and might choose the &quot;best&quot; one based on a complex algorithm\nthat depends upon price, flight length and flight time. In this case, we\nneed an information object (a flight list) that refers to other\ninformation objects (the flights). A data representation that has\nreferences embedded among data is known in Web terminology as &quot;hypermedia&quot;.\n\nListing things is a wonderful way of helping a client navigate to\ninformation because they know exactly what is available and sometimes\nknowing the list is as or more important as having access to any \nparticular item.\n\nGoogle is an example of an application that really does not care about\nany particular page on your site much, but cares very much about\nensuring that it has a relatively complete list of pages. So hypermedia\nis a very important part of web architecture because it allows\ndiscovery. Where possible, information delivered on the Web should be\norganized into webs of hyperlinked hypermedia documents.\n\nBecause the Web is basically a flat, global address space (modulo\nmachines behind firewalls etc.), any resource can refer to any other\nresource, no matter whether they use the same data representation or\neven the same access protocol (e.g. HTTP versus FTP). This promiscuous\nconnectedness is what makes the Web so great and important!\n\nThe great thing about using hypermedia as an organizational model for\ninformation repositories and services is that one process or individual\ncan direct another process or individual to look at and deal with a\nparticular resource by address and can choose the appropriate amount of\ncontext. For instance, you can direct a purchase order processing\napplication to a particular purchase order rather than to a whole\n&quot;purchase order application&quot;. This is in contrast to dominant web\nservices methodologies that hide many resources behind a single URI and\ntherefore makes addressing those individual resources impossible.\nImagine if someone wanted to send you a link to the Wall Street Journal\nand required you to always go to the front screen!\n\n    = Queries =\n\nSometimes the information provider has such a large database of\ninformation that it is not practically (or economically) feasible for it\nto deliver to the requestor in total or even to segment into many\nhypermedia documents. The requestor needs to specify some reasonable\nfilter. This is a fallback position because it becomes difficult or\nimpossible for the requestor to enumerate all of the information items\neven if this might be useful or important. Nevertheless, reality\nrequires that sometimes filtering happen on the server side and the Web\nallows this through HTTP URI &quot;query parameters&quot;.\n\nThe beautiful part of query parameters is that they are expressed as\npart of the URI so that all of the tools we&#39;ve built up for downloading\nordinary hyperdocument resources and lists of hyperdocument resources\ncan also be used on filtered lists of hyperdocument resources. The only\ndifference is that in this case, the URI is partially constructed by the\nclient application, under instructions from the server, rather than\nbeing constructed by the server and being totally opaque to the server.\nBut once the URI is constructed, it is as bonified a URI as any other\none and may be put into any slot expecting a URI. They can be\n&quot;promiscuously connected&quot;, cached, downloaded with command line tools,\nand so forth.\n\n    = Representations =\n\nAs the Web evolves it becomes increasingly clear that the concepts\naddressed by URIs and the bits available at those URIs have distinct\nlifecycles and properties. &quot;www.theonion.com&quot; is a news magazine. I\ncannot predict what bits you will get if you dereference on the day you\nread this essay. In order to discuss this distinction, we need words for\nthe thing that is addressed and the bits you get by going there on a\nparticular day, with a particular user agent, etc. The concept is known\nas a &quot;resource&quot;. The bits are known as a &quot;representation&quot;.\n\nRepresentations have media-types. Resources do not. In-so-far as\nresources are &quot;typed&quot; (and HTTP has nothing to say about this) you might\nsay that they are typed by RDF. The distinction between representation\nand resource allows us a very powerful form of extensibility and\nadaptability. The Web has a feature called content negotiation which\nallows resource consumers to ask for the resource in a variety of\ndifferent representations. One representation might be WML optimized for\nhand-held computers. Another might be XHTML optimized for browsers.\nOthers might be PDF optimized for printers and RDF optimized for machine\ndiscovery. As new standards come into existence, they can be served as\nnew representations for the information, enabling evolution of the\nresource without backwards compatibility problems.\n\nThis is a good point to emphasize something that has been so-far\nimplicit. There is nothing in the Web architecture which is specific to\ninteractions with a human being at one end and a machine at the other.\nExisting information resources can be made machine-accessible by adding\nan XML (or XML/RDF) representation alongside existing HTML\nrepresentations. Human beings are one kind of client for web resources.\nMachines are another.\n\n    = Services =\n\nSo far we have described the Web as an information publishing platform.\nBut over the years it has also become the world&#39;s leading service\npublishing platform. There are services for bidding on auctions, booking \nflights, generating insults and anything else you might dream of. The\nbiggest distinction between publishing information and publishing a\nservice is that the service may require the service provider and client\nworking together to generate new resources, change existing resources or\ndelete resources. In other words the conversation is two-way rather than\none-way.\n\nNow before we go into detail on services I want to point out that an\nimportant sub-task in publishing almost any service is publishing\ninformation either held by or relating to that service. There is a\ntendency to forget this when developing services using technologies such\nas SOAP and XML-RPC. For instance a part of a stock purchasing service\nmight include a means to get the stock price. The traditional\nSOAP/XML-RPC way to do this is to invent a new method called\ngetStockPrice. I have already discussed the interoperability limitations\nof this model. So the first thing to remember about publishing services\nis that whatever you do, do not neglect the information publishing part\nof your service. If it can benefit from the web architecture features\ndescribed above, use them.\n\nThe second important thing to remember about publishing services is that\npublishing information is crucial for the flexibility, reliability and\nscalability of your service. Let&#39;s deal with each of these in turn.\nImagine a service that allows the client and server to work together to\ngenerate a purchase order. Now they need to decide what to do with the\ngenerated purchase order. One option is that each of them can give the\norder a unique identifier (e.g. &quot;PO number&quot;) and maintain a local copy\nof it. This arrangement makes it difficult to bring third parties into\nthe conversation and to utilize URI-aware tools like spiders, caches,\ninferencers and XSLT transformation engines. It would be better to give\nthe purchase order its own URI. Generally, if there is information that\nis of interest to both or all participants in a conversation, that\ninformation should be given a URI so that new participants can be easily\nbrought in after the fact.\n\nAnother aspect of flexibility is allowing a variety of different kinds\nof clients. As long as the purchase order has a URI, the client can\ndecide how stateful or stateless it should be. If it wants to keep a\ncopy of the purchase order it can (more robust and paranoid clients\nwill). But if it wants to let the server manage it, it can merely keep\nthe URI and refresh from the server when it needs information. In a case\nwhere the server is allowed to unilaterally change the information\nresource (i.e. not a purchase order), the client can always get the\nlatest version of the resource using a GET.\n\nEmphasizing the information publishing portion of your service is also\nimportant for reliability reasons. Continuing with the purchase order\nexample, consider what would happen if the client party missed a message\nor had its state corrupted during the communication. As long as all\nrelevant information has been exposed on the server as URIs, it could\nrebuild its state with nothing more than the URI representing the\nresource. Conversely, in situations where the state of the conversation\nis implicit, one lost message can throw the client irreconcilably out of\nsync with the server. Of course if the service consumer somehow loses\nthe URI for the thing it is talking about (e.g. the purchase order URI)\nthen you are in trouble. But even then you can use discovery and query\ntechniques to re-establish contact. For this and other reasons, resource\ndiscovery should always be an important part of service design.\n\nFinally there is the issue of scalability. It is often the case that\nonce an information resource has been created, a representation of it is\nretrieved many times. Even a purchase order may be read over and over\nagain by internal and external auditors and order fulfillment systems.\nUsing standard web techniques, these representations can be cached.\n\nSo far, I&#39;ve tried to show how information publishing is a crucial part\nof all service publishing projects and thus to show that the service\npublishing problem is an _extension_ of the information publishing\nproblem, not a different problem altogether. Next we will describe how\nwe can extend the web architecture into service publishing.\n\n   = Resource construction and mutation =\n\nConsider a service like buying sneakers. There are three reasons that we\nneed to move beyond the GET-based web we have described. First, we will\nwant to create purchase orders, so we need a way to create objects.\nSecond, we need information to flow from the customer to the service\nprovider rather than vice versa. Third, we need to allow the &quot;side\neffect&quot; of actually shipping the shoes.\n\nThe HTTP method designed for creating and mutating objects, with\npossible side effects, is POST. POST is neither more nor less powerful\nthan GET. It is just different. GET&#39;s safety (side-effect-freeness)\nmeans that clients have extreme flexibility in structuring applications\nthat rely heavily on GET. In particular, GET allows very &quot;declarative&quot;\napplications that say what needs to be done but does not provide any\ninstructions on how to do it. For instance if an XSLT stylesheet needs\nto deal with an XML element inside of a web resource it can retrieve\nthat document once, or ten times, or a hundred times, at its own\ndiscretion. It might choose to do it once to optimize for bandwidth or a\nhundred times to optimize for client-side memory space. If the XSLT is\nusing multiple documents, it can also choose the order that it retreives\nthem at its own discretion.\n\nBut if you do need side-effects then you need to give up some of GETs\nadvantages. Then you need POST. Because POST invocations may have side \neffects, you must be very careful about the order in which you invoke \nPOST methods. You need to add the shoes to the shopping cart before you \ncheckout of the online store and not vice versa.\n\nPOST has another related strength/weakness. The input to GET is very \nsimple: basically just an address. The Web infrastructure strongly \nencourages you to move retrievable information into an addressable URI. \nBut when the service provider and client are working together to create \nnew resources or modify existing ones, they both need to contribute \ninformation. This requires a higher level of coordination which makes \nPOST-based integration more difficult than GET-based integration. But \nthis is the price of solving the more difficult problem of building \ninformation resources rather than simply delivering them.\n\nPOST and GET work together in important ways. Using GET-based navigation \nyou can find the service you want to invoke. It could even report its \nquality of service characteristics, terms and conditions and so forth. \nThen you use POST to invoke it. This will usually either mutate or \ncreate a resource. This resource has a URI that you can use GET to \nretrieve whenever you need it. You can also refer third parties at the \nresource via its URI and they can GET it. There is no need to coordinate \nwho GETs first or how many times you GET because GET is safe and idempotent.\n\nPOST can handle any operation which changes client-side state in a \nmanner that would be inappropriate for GET. But there are two operations \nthat have pretty clear semantics that can be separated out from the mass \nof POST-based actions. Sometimes you have a URI and you want to \noverwrite its content. For instance you load a document into your word \nprocessor, make a few changes and want to save it back. Or you are \nmaintaining a stock quote service and it is your job to udpdate the \nquotes as the most recently quoted price change. PUT allows these. The \nother operation is DELETE for destroying resources (i.e. making them \ninto 404s).\n\n\n\n\n\n"}}