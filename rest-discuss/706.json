{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":23186829,"authorName":"Paul Prescod","from":"Paul Prescod &lt;paul@...&gt;","replyTo":"SENDER","senderId":"bfBr4Ptria9z8skFknC844I00wEpvuZx-5xs84inZs-df2tRCQSEMyWXYpe__kesn6gR1_d-pMACrOWEnWiQ_iw_rTf2BQ","spamInfo":{"isSpam":false,"reason":"0"},"subject":"RFC: Part 2","postDate":"1013392761","msgId":706,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDNDNjcyNTc5LjY0Mzc4RDJEQHByZXNjb2QubmV0Pg=="},"prevInTopic":0,"nextInTopic":707,"prevInTime":705,"nextInTime":707,"topicId":706,"numMessagesInTopic":3,"msgSnippet":"The first part is at xml.com. I d like comments on the second part to be published later this week. Thanks in advance! ==== REST, Resource Modeling and the","rawEmail":"Return-Path: &lt;paul@...&gt;\r\nX-Sender: paul@...\r\nX-Apparently-To: rest-discuss@yahoogroups.com\r\nReceived: (EGP: mail-8_0_2); 11 Feb 2002 02:01:30 -0000\r\nReceived: (qmail 2254 invoked from network); 11 Feb 2002 02:01:30 -0000\r\nReceived: from unknown (216.115.97.172)\n  by m10.grp.snv.yahoo.com with QMQP; 11 Feb 2002 02:01:30 -0000\r\nReceived: from unknown (HELO smtp1.ActiveState.com) (209.17.183.249)\n  by mta2.grp.snv.yahoo.com with SMTP; 11 Feb 2002 02:01:30 -0000\r\nReceived: from smtp3.ActiveState.com (smtp3.ActiveState.com [192.168.3.19])\n\tby smtp1.ActiveState.com (8.11.6/8.11.6) with ESMTP id g1B21Rk19308\n\tfor &lt;rest-discuss@yahoogroups.com&gt;; Sun, 10 Feb 2002 18:01:27 -0800\r\nReceived: from prescod.net (ssh1.ActiveState.com [192.168.3.32])\n\tby smtp3.ActiveState.com (8.11.6/8.11.6) with ESMTP id g1B21Pe08683\n\tfor &lt;rest-discuss@yahoogroups.com&gt;; Sun, 10 Feb 2002 18:01:25 -0800\r\nMessage-ID: &lt;3C672579.64378D2D@...&gt;\r\nDate: Sun, 10 Feb 2002 17:59:21 -0800\r\nX-Mailer: Mozilla 4.76 [en] (Windows NT 5.0; U)\r\nX-Accept-Language: en\r\nMIME-Version: 1.0\r\nTo: &quot;rest-discuss@yahoogroups.com&quot; &lt;rest-discuss@yahoogroups.com&gt;\r\nSubject: RFC: Part 2\r\nContent-Type: text/plain; charset=us-ascii\r\nContent-Transfer-Encoding: 7bit\r\nX-Filtered-By: PerlMx makes it fast and easy.  See http://www.ActiveState.com/Products/PerlMx/Header\r\nFrom: Paul Prescod &lt;paul@...&gt;\r\nX-Yahoo-Group-Post: member; u=23186829\r\n\r\nThe first part is at xml.com. I&#39;d like comments on the second part to be\npublished later this week. Thanks in advance!\n====\nREST, Resource Modeling and the Real World\n\nIn the last article I described a new model for Web Services\nconstruction. It is called REpresentational State Transfer and applies\nthe principles of the Web to transaction-oriented services, rather than\npublishing-oriented sites. When we apply the strategy in the real world,\nwe do so using Web technologies such as URIs, HTTP and XML. Unlike the\ncurrent generation of Web Services technologies, however, we make those\nthree technologies central rather than peripheral. We rethink our web\nservice interface in terms of URIs, HTTP and XML. It is this rethinking\nthat takes our web services beyond the capabilities of the first\ngeneration. \n\nIn this article I want to discuss the applicability of several industry\nbuzzwords such as reliability, workflow, orchestration, security,\nasynchrony, auditing and so forth. Intuitively, it seems that the Web\ntechnologies are not sophisticated enough to handle the requirements for\nlarge-scale inter-business commerce. Those who think of HTTP as a\nsimple, unidirectional GET and POST protocol will be especially\nsurprised to learn how sophisticated it can be. \n\nQuick Review\n\nREST is a model for distributed computing. It is the one used by the\nworld&#39;s biggest distributed computing application, the Web. When applied\nto web services technologies, it usually depends on a triumvirate of\ntechnologies designed to be extremely extensible: XML, URIs and HTTP.\nXML&#39;s extensibility should be obvious to this most, but the other two\nmay not be. \n\nSimilarly there are an infinite possible of possible URIs. But, more\nimportant, they can apply to an infinite number of logical entities\ncalled &quot;Resources&quot;. URIs are just their addresses. Some REST advocates\ncall the process of bringing your applications into this model Resource\nModeling. This process is not yet as formal as object oriented modeling\nor entity-relation modeling but it is related to those. The strength and\nflexibility of REST comes from the creative use of URIs. \n\nHTTP&#39;s extensibility stems primarily from the ability to distribute any\npayload with predefined or new headers using predefined or (on occasion)\nnew methods. What makes HTTP really special among all protocols,\nhowever, is its implicit understanding of URIs and resources. URIs are\nthe defining characteristic of the Web: the glue that makes it work and\nscale. HTTP as a protocol keeps them front and center by defining all\nmethods as operations on URI-addressed resources. \n\nAuditing and Securing REST Web Services\n\nThe most decisive difference between web services and previous\ndistributed computing problems is that web services must be designed to\nwork across organizational boundaries. Of course, this is also one of\nthe defining characteristics of the Web. This difference has serious\nimplications with respect to security, auditing and performance. At the\ncore of the Web&#39;s solution to these problems is the same construct that\nis at the core of the Web&#39;s solution to everything: URIs. By modeling\nthe right combination of resources, addressed through URIs, we can build\nextremely secure systems. \n\nIn the previous article I discussed how it is possible to use ACLs to\nsecure services which use URIs as their organizational model.\nAdministrators can apply ACLs to the service itself and to every\ndocument that passes through the service, because each of them would\nhave a URI. As two business partners work their way through a process,\neach step would be represented by a new document with an attached ACL.\nOther partners (or auditors) could be given access to this document\nlater merely by manipulating the ACLs. Another model for security is\ncalled capabilities. This less popular model is more flexible than ACLs\nand is nevertheless compatible with second-generation Web Services. \n\nIn the REST model, both business partners would have a shared view of\nthe URI-space representing the process. Rather than sending each other\nbusiness documents through an email-style pipe, they would put them on\nmutually visible websites with shared URIs and passwords. These could be\neasily checked for discrepancies. Third parties can be brought into the\nprocess (perhaps for auditing) merely by pointing them at one or both of\nthe URIs. Standard HTTPS and HTTP authentication and authorization would\nbe sufficient to keep intruders from also being able to look at the\ndocuments. \n\nOf course HTTP-based Web Services can go through firewalls easily. But\nthat is the only point of similarity with RPC tunnels through HTTP such\nas XML-RPC or SOAP-RPC over HTTP. When you use HTTP over a firewall, you\nare being very explicit about what is going on. Your system\nadministrator can look at her logs to determine what services are\nrunning and who is accessing them. She can disable PUT or POST to make\ncertain parts of the service read-only. She can use standard filtering\nand hacker detection tools. When you use HTTP you and the system\nadministrator are on the same team. \n\nConversely, when you tunnel XML-RPC or SOAP through a firewall, you are\ndeliberately subverting her work and reducing the efficacy of her tools.\nBecause you are hiding your real actions in the XML body, you make it\nmuch harder for her to use standard filtering tools. This greatly\nexpands the opportunity for new security holes! \n\nService Context\n\nPeople building web services often complain that the &quot;tricky bit&quot; of web\nservices is maintaining shared context. For instance, context might\ninclude: \n\nWhere are we in this business process? \nWhat transactions have we done in the past? \nAre there any resources that I promise to hold for you? \nAre there any notifications I promise to deliver to you later? \nWhat permissions do you have? \n\nThere are three main ways that two partners can share context. One is to\nsend the entire context with every message. This is obviously not very\nscalable. As the relationship deepens the context will grow larger and\nlarger. Another option is to merely require each partner to keep context\nprivately and presume that the other partner has the same idea of\ncontext. As you can imagine, this is quite unreliable. A network hiccup\nor programming bug could make the contexts diverge. The mechanism used\non the Web today is to assign URIs to the context. For instance on\nExpedia there is a &quot;My Itinerary&quot; URI for each individual. Within that,\nevery purchase you have recently made has its own URI. While you are\npurchasing a new ticket, each step in the process is represented by\nanother URI. \n\nThe same principle applies to business-to-business processes. Of course\nthere will be some differences. Typically the canonical format for\ncontext in a business process with be XML. HTML will be generated as a\nview on that XML. But do not underestimate the importance of that\nhuman-readable view! Business partners will probably be careful to store\na copy of the context in case of network outage, programming bug or\noutright fraud.\n\nThis is precisely what the HTTP and the REST model were designed to\nallow. Remember that REST stands for REpresentational State Transfer.\nThe HTTP client transfers the state (the context) from the server to the\nclient using a representation like XML or HTML (depending on its needs).\nContext information can be linked together with XLink or RDF. Each bit\nof it can be individually secured using ACLs or capabilities. This\nmechanism for handling context seems so obvious to me as to be near\ninevitable. \n\nOrchestration\n\nEvery method that can be invoked on a resource or service is a possible\nconnector between the client and the service. If there are a hundred\nmethods then there are a hundred connectors. If every service has a\nhundred different methods then your connections become very complex -\nessentially point-to-point integrations rather than reusable patterns. \n\nThere are various systems in the computing world that have proven the\npower of having just a few methods rather than many. For instance, every\ntrue Unix hacker knows that the command line is incredibly powerful\nbecause it is possible to pipe data from one process to another using\nthe redirection &quot;methods&quot;, &quot;&gt;&quot;, &quot;&gt;&gt;&quot;, &quot;&lt;&quot;. The other Unix command line\ntools act as standardized filters and transformers connected by these\nmethods. \n\nSimilarly, if you think of a SQL table as a resource, the methods SQL\nmakes available are only SELECT, UPDATE, INSERT and DELETE. The rest of\nSQL is a set of transformers and filters that allow you to combine these\nmethods into services. .NET My Services has Query, Insert, Replace,\nUpdate and Delete. As I showed in the last article, UDDI has get_*,\ndelete_* and save_*. This pattern is ubiquitous. \n\nHTTP has GET, PUT, POST and DELETE. Anything that can be done with SOAP\nRPC or any other RPC can be done with those four methods. In fact, it is\nprecisely because HTTP has few methods that HTTP clients and servers can\ngrow and be extended independently without confusing each other. Rather\nthan invent new methods they find ways to represent new concepts in data\nstructures (increasingly XML data structures) and headers. \n\nNow that we&#39;ve boiled down our system to these basic methods, it turns\nout that we have the beginnings of a web service coordination,\norchestration and assembly language. I could imagine defining a new web\nservice as easily as: \n\ni = GET http://www.stockquotes.com/xmlquotes?IBM \nm = GET http://www.stockquotes.com/xmlquotes?MSFT \nif i &gt; m:\n    WITH AUTHENTICATION $myuserid $mypassword \n    POST http://www.etrade.com/stocks/IBM  \nelse: \n    POST http://www.etrade.com/stocks/MSFT  \n \nOr maybe we don&#39;t need a new language. Perhaps we could incorporate\nthese principles into existing scripting languages. The point is that\nunifying the method vocabulary of the web provides tremendous\nopportunities for simplifying interactions. Nobody learning a new web\nservice would ever have to learn the semantics of the various methods\nagain. Web services can be combined through simple Unix-style pipes: GET\nthis, GET that, transform, PUT there. \n\nOf course there is no free lunch. Using someone else&#39;s web service\nrequires you to understand their data structures (XML vocabulary and\nlinks between documents). But this is true whether we use REST or SOAP\nRPC. RPC APIs merely hide the problem behind an extra layer of\nnon-standardization. First you must figure out the method names\navailable. Then you must still figure out the data structures that may\nbe used as parameters. And then behind those data structures is the\nimplicit data model of the web service. UDDI has an implicit relational\ndata model. .NET My Services has a concept of a &quot;virtual document&quot;. The\nwhole thing would be simpler if the implicit data model was directly\nexposed as XML documents available as URI-addressed resources through\nHTTP. This in no way dictates the underlying implementation but it is\nbased upon a shared, web-wide data model that allows for easy\ncoordination! \n\nOnce you begin to orchestrate multiple web services, transaction\nprocessing becomes much harder. HTTP does not have a magical solution to\nthis problem but neither do specifications such as SOAP or ebXML. The\nsolutions proposed by the OASIS Business Transactions working group are\ncurrently protocol agnostic and should work fine with HTTP, once a\nbinding is formalized. A more complete analysis of their integration\nwith REST would be an interesting project, but it has not been done yet.\n\nAsynchrony\n\nPeople often complain that HTTP is not asynchronous. Unfortunately they\noften mean different things by that term. Most often they compare it to\nSMTP as an example of an asynchronous protocol. But you could make the\ncase that both are synchronous or asynchronous depending on how you\ndefine those terms. Both are synchronous in that you cannot send a\nmessage without waiting for a reply from the server. If an SMTP server\napplication is badly written, it can hold a connection open for hours,\njust as a badly written HTTP web service might. Similarly, both can be\nconsidered asynchronous in the sense that servers (HTTP or SMTP) never\nknow when they will get a request from a client. Requests are not\ncoordinated in advance. If one HTTP server makes a request to another\nthen it is exactly as synchronous or asynchronous as one SMTP server\nmaking a request to another. \n\nEmail is asynchronous not primarily because of SMTP itself, but the\ncollection of software that does store-and-forward, failure notification\nand replies. In an XML web services world, much of this must be\nrewritten to deal with URIs so as to manage shared context. For\ninstance, every message that passes through a web service should\nprobably be given a persistent HTTP URI for auditing purposes.\nSimilarly, the reply-to header should refer to an HTTP resource, not an\nemail address. Although early web services will of course build on\nwhatever software is already available, the vast majority of it will be\nwritten from scratch. I feel that it would make little sense to spend\nthe effort adapting a non-Web integrated protocol like SMTP to the Web\nrather than merely using HTTP. \n\nStill, it would require extensions to HTTP to offer all of the features\nof SMTP (in addition to HTTP&#39;s own unique features). Primarily, HTTP\nneeds a concept of &quot;callback&quot; or &quot;notification&quot;. Although this has been\ndone many times in many places, there is no single standardized way to\ndo this. Software dealing with notifications is not as reusable as other\nHTTP-based software modules. There is work under progress to correct\nthis situation, under the name &quot;HTTPEvents&quot;. Second, HTTP needs concepts\nof explicit and implicit store and forward relays, transformational\nintermediaries and return paths. These may be borrowed from SOAP headers\nand SOAP Routing. In fact, some REST proponents believe that this is the\nonly part of SOAP that is strongly compatible with the Web and HTTP. \n\nIn summary, various kinds of asynchrony are certainly possible in HTTP.\nMany commercial applications have been built using HTTP in a\npeer-to-peer, asynchronous fashion, by companies as large as Microsoft\nto as small as KnowNow. But there is active effort standardizing the\napproach taken on the REST list. \n\nReliability\n\nNetworks are inherently unreliable and the Internet is an extreme case\nof this. You must build network-based software to cope with failure no\nmatter what protocol you are using. Nevertheless, a combination of\nsoftware and protocols can make message delivery more reliable than it\nwould otherwise be. What most people ask for is that a message be\ndelivered if at all possible, and be delivered at most once. If it is\nnot possible to deliver then it should be reported to the application. \n\nWriting reliable-delivery software with HTTP is relatively easy. Thanks\nto the guarantees of TCP, you can always know for sure if you received\nan appropriate response. If you did not, then in many cases it is safe\nto repeat the message send, due to the principle of idempotency. In\nother cases it takes a slight permutation of the service to make it one\nthat builds upon idempotency. Although this is not rocket science, a\nfull description does take more than a couple of paragraphs. \n\nThe bottom line is that software written on top of HTTP can make all of\nthe same guarantees that expensive message queuing software can. Once\nyou have done that, the only difference is that the message queuing\nsoftware builds reliability around a proprietary protocol that cannot\n(typically) be used between business partners! If you would like to use\nthe message queuing software within your single organization then you\ncan easily tunnel HTTP on top of it and get the best of both worlds. \n\nCase Studies\n\nDespite its advantages, HTTP-based, URI-centric resource modeling is not\na common way of thinking about networking issues and REST-based web\nservices are not very common. On the other hand, useful, scalable,\npublic RPC-based web services are also quite difficult to find. The most\nobvious examples of HTTP-based web services are actual web sites. Any\nsite that presents a purchasing process as a series of web pages can\ntrivially be changed to do the same thing with XML. People who go\nthrough this process get all of the benefits of REST web services and\nnone of the expense of re-implementing their business logic around a\nSOAP-RPC model. \n\nTwo businesses that have created (admittedly simple) REST web services\nare Google and O&#39;Reilly. Google offers to its subscribers the ability to\nhave search results published as XML rather than HTML. This makes it\neasy to build various sorts of sophisticated programs on top of Google\nwithout worrying about shifting HTML formats. Unfortunately the public\nversion of Google no longer supports the XML feature. Presumably there\nwas some danger it would undermine the banner-based business model!\nNevertheless, REST was a natural fit for Google. Essentially all they\nhad to do was change their HTML generating code to XML and they had a\nWeb Service instead of a Web Site. \n\nThe Meerkat Example\n\nO&#39;Reilly&#39;s Meerkat is one of a very few useful, public web services.\nUnlike the majority of the services described on XMethods, Meerkat is\nused by thousands of sites every single day. \n\nMeerkat uses the three foundation technologies of second-generation web\nservices. It uses a standardized XML vocabulary: RSS. Meerkat would\nnever have become as powerful and scalable if it had invented its own\nvocabulary. It absolutely depends on the fact that it can integrate\ninformation from hundreds of sites that use the RSS vocabulary and the\nHTTP protocol. \n\nIn addition to using HTTP and RSS, Meerkat uses URIs as its addressing\nscheme. It has a very sophisticated URI-based &quot;API&quot; described here:\nhttp://www.oreillynet.com/pub/a/rss/2000/05/09/meerkat_api.html \n\nMeerkat&#39;s content is also available through an XML-RPC API described in\nhttp://www.xml.com/pub/a/2001/07/18/excerpt/xml-rpc.html. Before the\nREST philosophy was popularized it was not clear that Meerkat&#39;s\nHTTP/XML-based interface was already a complete web service! It would be\nan interesting project to compare and contrast these two interfaces in a\nformal essay. \n\nOne interesting point, however, is that all of Meerkat&#39;s content\naggregation is done through HTTP, not XML-RPC or SOAP. It would be\nludicrous to suggest that every content publisher in the world should\nnot only support XML-RPC and SOAP but also some particular set of\nmethods. This would be the situation if instead of inventing the RSS\nvocabulary the world had standardized the &quot;RSS web service interface.&quot; \n\nTo be fair, HTTP&#39;s advantages would have been less pronounced if\nMeerkat&#39;s interaction with these sites had required two-way\ncommunication instead of a simple one-way information fetch.\nNevertheless, there is nothing particularly difficult about using HTTP\nin a two-way fashion. It is a virtue of HTTP that it is much easier than\nother models for one-way (&quot;data publishing&quot;) services and not much\nharder to use for bi-directional, transactional services. \n\nMeerkat shows that when many sites share an XML vocabulary, a protocol\nand a URI namespace, new services arise organically. It is arguably the\nfirst equivalent in the Web Services world to a large-scale, distributed\nservice like Yahoo. Meerkat&#39;s success suggests strongly that the most\nimportant enabler of large-scale, distributed web services will be\ncommon XML vocabularies. \n\nREST limitations\n\nThere is no free lunch. REST is not a panacea. The biggest problem most\nwill have with REST is that it requires you to rethink your problem in\nterms of manipulations of addressable resources instead of method calls\nto a component. Of course you may actually implement it on the server\nside however you want. But the API you communicate to your clients\nshould be in terms of HTTP manipulations on XML documents addressed by\nURIs, not in terms of method calls with parameters. \n\nYour customers may well prefer a component-based interface to a REST\ninterface. Programmers are more used to APIs and APIs are better\nintegrated into existing programming languages. For client-side\nprogrammers, REST is somewhat of a departure although for server-side\nprogrammers it is not much different than what they have been doing for\nthe last several years. \n\nThe client side may get easier in the future. It may be possible to use\nWSDL to map URIs to logical operations that can in turn be mapped to\nmethod calls in a programming language. Although this is described in\nthe WSDL specification, implementations of this feature are few and far\nbetween. Even so, RPC will likely always be easier than REST. If a\nparticular problem can be solved with RPC and future extensibility is\nnot an issue then you should certainly use the simpler approach. \n\nHTTP is also not appropriate in some circumstances. Because HTTP runs on\ntop of TCP, it can have high latency. HTTP is designed primarily for the\nkind of coarse-grained interactions that are used on the public\ninternet, not the kind of fine-grained ones that might be appropriate on\na single desktop, within a department or even in certain enterprise\nsituations. Once again, if DCOM or CORBA solves your fine-grained\nproblem then there is no reason to move to REST. In my opinion, REST\nwill dominate primarily in the world of partner-facing, external Web\nServices. \n\nWhy REST is the next Generation\n\nLet&#39;s say that ACME Inc sets up a major web service (like UDDI) using\nthe SOAP RPC philosophy. BARTEL Inc. sets up a competing web service\nusing the HTTP philosophy. Customers will gravitate to the REST-based\none because it will be simpler on almost every measurable axis: message\nsize, message complexity, number of concepts (URI versus a dozen other\nnaming schemes) and compatibility with their existing systems. The\nservice can be automatically and instantly accessible from any device\nthat can do HTTP and XML. The Context Problem will be much more\ntractable. Management will appreciate the service&#39;s ease of maintenance,\ntesting and security. \n\nBut REST will really win out over the long term when the two services\ntry to evolve. The REST-based service uses the most flexible naming and\naddressing scheme ever invented. It can instantly incorporate a\npeer-to-peer model by allowing references to data on PCs. When they\ninvent a way to make data on cell phones URI-addressable, every cell\nphone will be able to integrate data with the service. \n\nThe rhetoric around web services describes them as &quot;like the web, but\nfor machine to machine communications&quot;. They are said to be a mechanism\nfor publishing processes as the Web published data. REST turns the\nrhetoric into reality. With REST you really do think of Web Services as\na means of publishing information, components and processes. And you\nreally do use the technologies and architecture that make the Web so\neffective.\n\n"}}