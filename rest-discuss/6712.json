{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":228155998,"authorName":"Mike Schinkel","from":"&quot;Mike Schinkel&quot; &lt;mikeschinkel@...&gt;","profile":"mikeschinkel","replyTo":"SENDER","senderId":"blB10SlnIyL2871ffa6QYi4v7_9vGrCzObw41gM4VaeoInGigNh0LkKPhN6n8Y0_ryBpwD7g26DZm7XfLBx4FynvS3SmMbtE2_1qNR9fRg","spamInfo":{"isSpam":false,"reason":"0"},"subject":"RE: &quot;Lightweight Data Access Services&quot; and Well Designed Urls[rest-discuss]","postDate":"1162278463","msgId":6712,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDAwM2EwMWM2ZmNiYiQ0MzQ0NmVjMCQwNzAyYThjMEBHdWlkZXMubG9jYWw+","inReplyToHeader":"PDExNjIyNDgxNDAuNDYzNS40MC5jYW1lbEBsb2NhbGhvc3QubG9jYWxkb21haW4+"},"prevInTopic":6711,"nextInTopic":6713,"prevInTime":6711,"nextInTime":6713,"topicId":6685,"numMessagesInTopic":35,"msgSnippet":"Benjamin: Thanks for the email. (Note, my response is REALLY LONG. Sorry in advance.) ... in fact be based soundly in ideas that you haven t come to grasp","rawEmail":"Return-Path: &lt;mikeschinkel@...&gt;\r\nX-Sender: mikeschinkel@...\r\nX-Apparently-To: rest-discuss@yahoogroups.com\r\nReceived: (qmail 26444 invoked from network); 31 Oct 2006 07:08:56 -0000\r\nReceived: from unknown (66.218.67.34)\n  by m40.grp.scd.yahoo.com with QMQP; 31 Oct 2006 07:08:56 -0000\r\nReceived: from unknown (HELO wx-out-0506.google.com) (66.249.82.232)\n  by mta8.grp.scd.yahoo.com with SMTP; 31 Oct 2006 07:08:56 -0000\r\nReceived: by wx-out-0506.google.com with SMTP id t11so1897390wxc\n        for &lt;rest-discuss@yahoogroups.com&gt;; Mon, 30 Oct 2006 23:07:45 -0800 (PST)\r\nReceived: by 10.70.32.13 with SMTP id f13mr6610345wxf;\n        Mon, 30 Oct 2006 23:07:44 -0800 (PST)\r\nReturn-Path: &lt;mikeschinkel@...&gt;\r\nReceived: from desktop ( [69.94.221.21])\n        by mx.google.com with ESMTP id 33sm6294621wra.2006.10.30.23.07.44;\n        Mon, 30 Oct 2006 23:07:44 -0800 (PST)\r\nTo: &lt;rest-discuss@yahoogroups.com&gt;\r\nDate: Tue, 31 Oct 2006 02:07:43 -0500\r\nMessage-ID: &lt;003a01c6fcbb$43446ec0$0702a8c0@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: text/plain;\n\tcharset=&quot;us-ascii&quot;\r\nContent-Transfer-Encoding: 7bit\r\nX-Mailer: Microsoft Office Outlook 11\r\nX-MimeOLE: Produced By Microsoft MimeOLE V6.00.2900.2962\r\nthread-index: Acb8dK3d17KEeW+iQhWTTMM5ruQ2iwALE4Lg\r\nIn-Reply-To: &lt;1162248140.4635.40.camel@...&gt;\r\nX-eGroups-Msg-Info: 1:0:0:0\r\nFrom: &quot;Mike Schinkel&quot; &lt;mikeschinkel@...&gt;\r\nSubject: RE: &quot;Lightweight Data Access Services&quot; and Well Designed Urls[rest-discuss]\r\nX-Yahoo-Group-Post: member; u=228155998; y=uSTF0lwnbvOMcNyekNVS7WYqiEtUady9wcArSqu3X5eOL_WwuqKQ\r\nX-Yahoo-Profile: mikeschinkel\r\n\r\nBenjamin:\n\nThanks for the email. (Note, my response is REALLY LONG. Sorry in advance.)\n\n&gt;&gt; But beware as a newcomer to REST that what you see as religious dogma may\nin fact be based soundly in ideas that you haven&#39;t come to grasp with, yet. \n\nI appreciate your comment, but I think you misunderstand my meaning and how\nI was using the term &quot;religious dogma.&quot;  In the manner I was using the term,\nby its very nature it would have no basis in sound ideas. And I don&#39;t mean\nto say there are not sound ideas, I&#39;m absolute certain there are. But what\nso often happens is that some people have a tendency to become zealots and\nelevate certain ideas to mythic proportion while at the same time perverting\nthem.  They both preach there &quot;gospel&quot; and follow it while not accepting the\npotential that there may be caveats for it&#39;s application. They resist\nallowing anyone to objectively analyze the applicability to alternate\nuse-cases. Logic and reason are no longer acceptable and replaced only by a\nstrict adherence to the dogma in verbatim form.  And usually, as appears to\nbe true in the case of URI opacity, the originator of the idea (Fielding)\nobjects to this dogmification!\n\nBut of course dogmification happens even more in the realm of politics and\nreligion, and I&#39;m probably just hypersensitive to it given the world events\nof the six years or so....  :)\n\nSo in summary, I&#39;m very interested in exploring the reasons behind the ideas\nso I can gain a firm grasp of their value. However I will strenuously object\nif people tell me the ideas can&#39;t be questioned, especially if the\njustifications I&#39;m given for the ideas are circular in definition.\n\n&gt;&gt; The constraints of REST exist for specific reasons. \n\nAnd I would assume that that would be true.  Certainly the people involved\nin defining REST (Fielding, et. al.) are both visionary and briliant so it\nwas foolishly arrogant for me to think otherwise, which I don&#39;t.\n\nThe problem I have been having on the lists is that many people constantly\nargue this point without ever actually defining what those actual\nconstraints are and without giving reasons why each constraints exist.\nFurther, I have had a very hard time finding actual clear and concise\ndefinitions of exactly what are the constraints for REST in terms that are\neasy to understand. What I have found are rigorous definitions like Fielding\nprovided in his dissertation which I struggle to follow.  \n\nI also have not been able to find clear and concise explanation of why each\nconstraint is important. This is probably because if I can&#39;t find an easy to\nunderstand list of constraint then I&#39;m certainly no going to find an easy to\nunderstand list of reasons for those constraint because the latter requires\nthe former!\n\nAnd I think this is partly why there is so much fruitless debate; few people\nreally do understand the constraints of REST and reasons for those\nconstraints. If more people did, there would be a lot more written about\nREST in layman&#39;s terms on the web, and there is not.\n\nUnderstanding them is equally important to be able to understand in what\ncontexts and for what use-cases the constraints do and do not apply. It made\nbe perfectly valid to relax one or more constraints in certain use-cases and\nI think this is what Fielding implied in his late email to the list. But\nwithout understanding the constraints and reasons, how will we ever figure\nout when we can safely ignore them?\n\nFurther, it&#39;s clear that time often reveals that certain aspects of software\narchitecture are important whereas other aspects are unimportant. Aspects\nfor which much effort is applied get little significant use, and other\naspects that amazingly became critical. One of more of REST&#39;s constraints\nmay fit into this category. For example there is content negotiation\ncapability in HTTP but it is almost never used on the web. And I know there\nare other examples, but since we no longer really utilize features that were\nignored it is hard for me to think of another example at the moment.) And\nfor things becoming critical TBL said in Weaving the Web Chapter 4 page 42\n&quot;...the human readability of HTML was an unexpected boon. To my surprise,\npeople quickly became familiar with the tags and started writing their own\nHTML documents directly.&quot;  \n\nSo I have an intuition that, in some contexts and some use-cases, some of\nthe constraints of REST are not that important.  But without being able to\ntruly understand the constraints and the reasons for the constraints, and\nwithout having people willing to discuss constraints and the reasons for the\nconstraints I cannot confirm or lay to rest (no pun intended) my intuition\non this matter.  Instead I get debate in support of and blind adherence to\nthe dogma.  After all, this isn&#39;t really a religion; we *can* apply logic\nand reason to it and not have to just accept it on faith.\n\nDoes that not make sense?  (and sorry for rambling; I&#39;m still myself trying\nto clarify my thoughts on the matter.)\n\nAs an aside, from TBL&#39;s Weaving the Web Chapter 4 page 39 he says &quot;...if I\nhad insisted everyone use HTTP, this would also have been against the\nprinciple of minimal constraint. If the Web were to be universal, it should\nbe as unconstraining as possible.&quot;  This would seem to imply that relaxing\nthe constraints of REST whenever reasonable would be a good idea, no?\n\n&gt;&gt; I have seen many people come through this list arguing about whether one\nthing was more restful than another, when both were RESTful and the one\nbeing touted as &quot;more&quot; RESTful was also sillier. \n\nI concur on that point.\n\n&gt;&gt; However, to assume that there is no opacity constraint at all or \n\nI have actually spent the past week or so studying this issue of &quot;URI\nopacity.&quot;  I have searched for, found, and printed *almost*literally* every\nreference to the term URI Opacity on the web (I have a stack of printouts\nliterally three reams high on the subject.) After some pretty intense study\nI can say that, without hesitation, more than 90% of the people who discuss\nand debate URI opacity do not fully understand the concept and are either\ntreating it as dogma or attempting being heretical regarding the dogma.\n\nYes, there is a constraint of URI opacity. But it applies in far fewer cases\nthan most people arguing on its behalf seem to believe.  One reason for the\nURI opacity constraint is to ensure that agents such as proxies and routers\ndo not inspect certain parts of the URI&#39;s metadata and make modifying\nassumptions before forwarding the URI. In addition, URI opacity is important\nto decouple the meaning of an extension from the URL (i.e. .JPG may or may\nnot be an image file using the JPEG format), and to keep user agents from\nmaking assumptions about a resource based on a it&#39;s URI path, fragment, or\nquery string (they can make assumptions based on scheme and domain.) This\nlatter constraint can be restated as &quot;don&#39;t create or use &#39;well-known\nnames.&#39;&quot;\n\nBut the principle of URI opacity DOES NOT forbid the following:\n\n* To organize a website&#39;s URL structure with meaningful metadata\n* To publish the meaning of a website&#39;s URL metadata \n* For a client to utilize knowledge of a website&#39;s URL metadata \n\nAs a matter of fact, I have found several references where each of TBL, Roy\nFielding, Noah Mendelson, Dan Connally, etc. have recommended that\nwebmasters and web developers DO structure their URLs in human\nunderstandable manners. \n\nAnd back to the subject of REST, it has no constraint of URI opacity per se\n(and if Fielding contradicts me, I&#39;ll go spend the time to dig up the\nreferences to where he has said otherwise. :)\n\n&gt;&gt; to assume that new content types should be devised for each new service\non the Internet would also be faulty.\n \nHopefully nothing I said would have implied that because, at this point in\nmy understanding if seems very foolish to add new content types unless the\nis an overwhelming reason to do so.\n\n&gt;&gt; &gt;&gt; a resource does not change.\n&gt;&gt; A resource is like an object, and a url is like a pointer to \n&gt;&gt; that object. If I have the same pointer, it will be the same \n&gt;&gt; object at the other end of that pointer. Over time the state \n&gt;&gt; of that object may change, so when I GET it i&#39;ll retrieve \n&gt;&gt; different results. It still means the same thing.\n\nOkay, let me take a stab at it. Can we say &quot;A resource does not change its\nidentity?&quot;  \n\nAn analogy might be a human:  They have a name and in the USA a social\nsecurity number which are both analogous to a URL.  And over time they might\nget fat or loose weight and they will definitely get older, but they are\nstill the same person (I&#39;m ignoring that people unfortunately die and\nresources are not supposed to. :)\n\n&gt;&gt;&gt;&gt;&gt;&gt; The reason is independent evolution of components. \n&gt;&gt;&gt;&gt; (The reason for what?)\n&gt;&gt; I believe you&#39;ll find that this is the reason for URL opacity.... \n\nThanks, but that didn&#39;t answer my question.  You clarified his answer, but\nyou didn&#39;t answer my question which is &quot;What was the question?&quot;  (If that&#39;s\nstill not clear, think about the game show Jeopardy where they give you the\nanswer and you are supposed to guess the question.  I was asking: &quot;What was\nthe question?&quot;)\n\nThat said, your explanation brought up some other thoughts on the subject.  \n\n&gt;&gt; If I assume without being told that particular URL constructions \n&gt;&gt; exist, then I may be forcing the same web site provider over \n&gt;&gt; time or different web site providers at the same time to \n&gt;&gt; construct their URI spaces the same way. This limits evolution \n&gt;&gt; of the noun-space. \n\nThis makes the assumption that the &quot;I&quot; doing the assuming is a machine\n(client or user-agent.) It also assumes an arbitrary (set of) URI(s) for\nwhich the URI authority (i.e. website, etc.) has given no guidance regarding\nURI metadata.  If the URI authority chooses to, it is perfectly okay for it\nto publish the meaning of its URI metadata. And if a consortium of URI\nauthorities choose to do so, it is not wrong for all of them to publish URIs\nwith the same metadata structure.  The only prohibition is that the machine\nshould not simply &quot;assume&quot; without first being given specific knowledge of\nURI metadata by the URI authority.\n\nAlso, if the &quot;I&quot; in your statement is instead human there&#39;s no problem\nhumans have a built in error recovery mechanism called &quot;intelligence.&quot; The\nhuman will see that the URL is not there and then be able to decide what to\ndo next based on whatever is their goal.\n\n&gt;&gt; If I follow hyperlinks or fill out server-provided forms to \n&gt;&gt; discover the urls of particular resources then different \n&gt;&gt; servers or the same server over time have greater \n&gt;&gt; opportunity to evolve differently.\n&gt;&gt;\n&gt;&gt; Ideally, hypermedia would be used whenever a resource \n&gt;&gt; is being discovered. Obviously you have to start somewhere, \n&gt;&gt; but by finding hyperlinks in Location headers and documents \n&gt;&gt; and by filling out server-provided forms to locate more resources \n&gt;&gt; you should be able to get from point A to point B with a \n&gt;&gt; minimum of hassle. It is contingent on the service provider to \n&gt;&gt; ensure that navagability is considered. There should be a map \n&gt;&gt; on someone&#39;s whiteboard somewhere showing which resources \n&gt;&gt; a client is expected to find by out of band means, and how they \n&gt;&gt; get to everything they need to find from that point.\n\nAnd this begs questions I have that I have not seen anyone else asking, and\nthey are:\n\n1.) How does my machine figure out where the URL is that allows me to follow\nthese hyperlinks?  My machine has to find it somewhere, so we have a\nchicken-&-egg problem; once that first URL is published and then machines\nstart using it, it can no longer evolved without breaking the software\nrunning on the machines.  Right?\n\n2.) If machine retrieves the resource which contains a list of URLs that\nrepresent services (we are discussing REST here not end user content,\nright?) it must somehow know how to figure out which of those URLs represent\nwhich services.  Which means that there needs to be conventions for names\nembedded in that list of URLs, right?  (This is where I have *yet* to see or\nhave anyone provide me with an example of a hypermedia system for invoking\nREST web services.  Since I haven&#39;t been given any examples, I&#39;m going to\nsimply dream one up so I can discuss this issue.)  \n\nLet&#39;s assume my machine called http://rest.foo.com/v1.0/ and it returned a\nresource with an representation in XML like so:\n\n\t&lt;?xml version=&quot;1.0&quot;?&gt;\n\t&lt;Services&gt;\n\t\t&lt;Add&gt;http://rest.foo.com/v1.0/cryptic-path-for-add&lt;/Add&gt;\n\t\n&lt;Update&gt;http://rest.foo.com/v1.0/cryptic-path-for-update&lt;/Update&gt;\n\t\n&lt;Insert&gt;http://rest.foo.com/v1.0/cryptic-path-for-insert&lt;/Insert&gt;\n\t\n&lt;Delete&gt;http://rest.foo.com/v1.0/cryptic-path-for-delete&lt;/Delete&gt;\n\t&lt;/Services&gt;\n\nNow my machine could look for &quot;Services&#92;Add&quot; to get the URL for the &quot;Add&quot;\nservice and that would follow the REST hypermedia constraint, right?  But\ndon&#39;t I have to know to look for a hard-coded &quot;Services&#92;Add&quot; in order to\nfind the &quot;Add&quot; service?  Given that, I really see only a few significant\ndifferences between that and just know to add the metadata &quot;add/&quot; to the end\nof the same URL that needed to be published anyway:\n\n\thttp://rest.foo.com/v1.0/add/\n\nThere are only two things I lose by doing this:\n\n1.) Inflexibility regarding what resources can be placed within the URL\nhierarchy below http://rest.foo.com/v1.0/   Frankly, I don&#39;t see as problem.\nIf you want to put other things under *that* URL then I&#39;ll put the services\nAPI at a different URL.\n\n2.) Inability to have the services hosted on other domains or in other paths\nof the same domain.  Yes I can see this as a potential problem, but I would\nargue that it is as much a problem of routers and proxies and web server\nsoftware as it is of URI design because given the right systems a URL can be\nvirtualized and hosted anywhere; just because it appears in a subdirectory\nin the hierarchy the physical implementation doesn&#39;t require that it be.\nSaid another way, have the map to where each of your services physically\nresides be located behind the firewall not inside of a resource delivered to\nevery client that requests it.\n\nOTOH, if you implement the service simply by tagging the verbs onto the end\nof the main URL you gain significant simplicity and increase the ease of\nimplementation by going straight to the hard-coded URL\nhttp://rest.foo.com/v1.0/add/  People can test it in any browser I am\nalready using (assuming the service provides a test form), and any software\nthat can do a POST can call it; no extra code required.  IMO this is NO\nSMALL SHAKES in a world that is now looking for collaborative intelligence\nand is interested in empowering people to implement mashups.  \n\nSure the browser vendors and programming library vendors could ALL start\noffering improved functionality to make it transparent and/or easy to see\nand call and test REST services based on hypermedia as I&#39;m describing, but\nthe likelihood of that happening in a reasonable timeframe is slim to none,\nand it doesn&#39;t address all the browsers and programming libraries that are\ncurrently in use today.  And even if it did, we still don&#39;t know how long it\nwould take to identify a UI metaphor that would be effective in exposing\nthose new capabilities in a simple and easy to use manner.\n\nWhich brings me to my assertion regard my current understanding of REST and\nhypermedia: \n\nFor systems that need to be 100% robust and that are implemented by\nprofessional programmers and are typically for internal use or use with\nbusiness partners, REST should be deployed using hypermedia for the benefits\nit brings.  But for Internet-published APIs that occupational programmers\nand hobbyists will probably make use of in far greater percentages than\nprofessional programmers hypermedia is far too great a burden to impose and\nthe responsibility should instead be on the URI/API authority to correctly\ndesign and version their URLs such that they do not need to move or change\nthem over time. This will make it much easier for occupational programmers\nand hobbyists to build services, and significant improve adoption.\n\nThat said, I&#39;d love for you or anyone to shoot holes in my assertion if\nthere are holes in it.\n\n&gt;&gt; Consider the Web. You start from a home page plus bookmarks, \n&gt;&gt; and navigate out from there. You will often use a search engine \n&gt;&gt; form to construct a search url. When you go to that url you will \n&gt;&gt; hopefully find resources that are of use to you. Machines can \n&gt;&gt; follow similar patterns.\n\nPersonally, I often type in the URLs myself. For example, whenever I go to\nWikipedia now I type in &quot;en&quot; to get me to the dropdown to my life of recent\nWikipedia URLs (&quot;en&quot; for &quot;English&quot;) and then I remove the topic and replace\nwith whatever topic I want. And I fo straight to the page I want probably\n90% of the time.  That is FAR faster than using hypermedia to get there\nbecause I don&#39;t have to wait for intermediate pages to load.\n\nWhat&#39;s more, when I post to my blog and need to hyperlink, I am constantly\nconstructing URLs such as references to Flickr pictures, searching specific\nterms on Google, referencing books on Amazon, and so on. The more I am aware\nof the URL structure, the more quickly I can get my blog post done.  And if\nI can learn a URL structure I am FAR MORE LIKELY to reference a given\nresource on such a site.\n\nSo I think that the hypermedia navigation metaphor is great and valuable,\nclearly. I just don&#39;t think that it is the only viable and valid navigation\nmetaphor.\n\nAt this point two &quot;constraints&quot; occur to me for which I feel the need to be\nheretical:\n\n1.) The constraint that URI paths, fragments, and query strings need to be\nopaque: Well, the academics in ivory tower of standards may decree this, and\nthe clergy within the church of web architecture may preach this, but only\nspecialist technical professionals are even aware of this requirement!  On\nthe other hand, the reality is that many orders of magnitude more people are\nout there on the web using and interacting and assuming and programming and\nconstructing URLs than they are professionals who know they &quot;shouldn&#39;t&quot; be\ndoing so.  \n\nAnd the fundamental reasons those entrepreneurs and business people and\nhobbyist and occupational programmers are committing blasphemy is because:\n\na.) URLs are visible, \nb.) URLs frequently contain coherent metadata, and \nc.) There is great benefit to utilizing the metadata within URLs (see\nhttp://weblog.infoworld.com/udell/LibraryLookup/ for an example)\n\nSo we can argue and debate on this list all we want about how URIs should be\nopaque, but the VAST MAJORIT of people are going to ignore this advice\nbecause they&#39;ve never even heard it.  And even if they do hear it, they\nstill may ignore it because they won&#39;t get the benefits they want if they\nfollow the advice (see again the LibraryLookup project.) So in my opinion,\nFOR THE CASE OF THOSE WHO ARE NOT PROFESSIONAL PROTOCOL SPECIALIST\nPROGRAMMERS, we should embrace this reality instead of pedantically saying\n&quot;It should not happen&quot; or &quot;They should not do this&quot; and instead look to\npromote best practices to minimize the harm of URI transparency and instead\nleverage its benefits among the &quot;prols.&quot; :)   \n\nOf course router and proxy programmers should still follow the axiom of URI\nopacity because there are strong benefits for everyone if they do, and also\nbecause they should know better. ;)\n\n2.) The constraint that most users don&#39;t understand URLs anyway:  This may\nbe true, but every year it becomes less so because of both learning and the\nprocesses of aging, and if we instead proactively educated people about URLs\nby giving URLs greater profile on websites and in browsers then people would\nmore quickly learn their benefits and be able to use them even more\neffectively then they will if no action taken of this sort. BTW, education\nand advocacy regarding Url usage and design is why I started\nhttp://www.welldesignedurls.org/ in the first place.\n\n&gt;&gt; See also:\n&gt;&gt; http://rest.blueoxen.net/cgi-bin/wiki.pl?BenjaminsRESTTutorial\n&gt;&gt; http://rest.blueoxen.net/cgi-bin/wiki.pl?RESTfulDesign\n&gt;&gt; [1] http://www.ietf.org/internet-drafts/draft-gregorio-uritemplate-00.txt\n\nThanks.  Those are all in my three ream stack of printouts. I&#39;ve read the\nfirst two but not yet the thrid (I will read it next, thanks.)\n\nWHEW!  I didn&#39;t mean to write so much; I hope I didn&#39;t fill up anyone&#39;s\nemail inbox. :) \n\nAnd hope I didn&#39;t come across as attacking the messenger.  But I did need to\nget some of these things off my chest as I&#39;ve seen so much discussed about\nthese subjects yet I haven&#39;t seen anyone make the points I made.  \n\nI will also probably repurpose some of what I wrote above for future blog\nposts (with much editing and after sleeping on it and incorporating any\nfeedback.) \n\nThat said, I look forward to your input.\n\n-Mike Schinkel\nhttp://www.mikeschinkel.com/blog\nhttp://www.welldesignedurls.org/\n\nP.S. Did you know that Firefox prints out the content on the REST wiki one\npage per line?  http://rest.blueoxen.net/cgi-bin/wiki.pl?RESTfulDesign\ngenerates 117 pages!\n\n\n\n"}}