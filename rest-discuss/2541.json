{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":69125415,"authorName":"Mathews, Walden","from":"&quot;Mathews, Walden&quot; &lt;waldenm@...&gt;","profile":"waldenmathews","replyTo":"SENDER","senderId":"L2xdkFXzw0Z3nV0kuKJ9wrnTnILd9JopOwoJB-cAlaY9ZsYQ8icETOeB3lQISeB4bgb5wNczTt0NF8i0rBpAQQOP5wk4DPsehzA","spamInfo":{"isSpam":false,"reason":"0"},"subject":"RE: [rest-discuss] Rediscovering Web Architecture  from first pri\tnciples","postDate":"1031951602","msgId":2541,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PDEzNzNENjM0MkZBMUQ0MTE5QTUxMDBFMDI5NDM3RjY0MDQ1RUVDRTlAY2xpZmZvcmQuZGV2by5pbHguY29tPg=="},"prevInTopic":0,"nextInTopic":0,"prevInTime":2540,"nextInTime":2542,"topicId":2541,"numMessagesInTopic":1,"msgSnippet":"Paul, Stayed late at my desk on a Friday afternoon to read all the way through.  Nicely done, especially the part that explains why we need both resources and","rawEmail":"Return-Path: &lt;waldenm@...&gt;\r\nX-Sender: waldenm@...\r\nX-Apparently-To: rest-discuss@yahoogroups.com\r\nReceived: (EGP: mail-8_1_1_3); 13 Sep 2002 21:13:54 -0000\r\nReceived: (qmail 6878 invoked from network); 13 Sep 2002 21:13:54 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m13.grp.scd.yahoo.com with QMQP; 13 Sep 2002 21:13:54 -0000\r\nReceived: from unknown (HELO ilx.com) (199.119.33.232)\n  by mta2.grp.scd.yahoo.com with SMTP; 13 Sep 2002 21:13:54 -0000\r\nReceived: from clifford.devo.ilx.com (clifford.devadm.ilx.com [172.27.56.72])\n\tby ilx.com (8.11.0/8.9.3) with ESMTP id g8DLDNO34690;\n\tFri, 13 Sep 2002 17:13:23 -0400 (EDT)\n\t(envelope-from waldenm@...)\r\nReceived: by clifford.devo.ilx.com with Internet Mail Service (5.5.2653.19)\n\tid &lt;R9QJDYNW&gt;; Fri, 13 Sep 2002 17:13:23 -0400\r\nMessage-ID: &lt;1373D6342FA1D4119A5100E029437F64045EECE9@...&gt;\r\nTo: &quot;&#39;Paul Prescod&#39;&quot; &lt;paul@...&gt;, rest-discuss@yahoogroups.com\r\nSubject: RE: [rest-discuss] Rediscovering Web Architecture  from first pri\n\tnciples\r\nDate: Fri, 13 Sep 2002 17:13:22 -0400\r\nMIME-Version: 1.0\r\nX-Mailer: Internet Mail Service (5.5.2653.19)\r\nContent-Type: text/plain\r\nFrom: &quot;Mathews, Walden&quot; &lt;waldenm@...&gt;\r\nX-Yahoo-Group-Post: member; u=69125415\r\nX-Yahoo-Profile: waldenmathews\r\n\r\nPaul,\n\nStayed late at my desk on a Friday afternoon to read all the\nway through.  Nicely done, especially the part that explains\nwhy we need both resources and representations.  Very clear.\n\nWalden\n\n&gt; -----Original Message-----\n&gt; From: Paul Prescod [mailto:paul@...]\n&gt; Sent: Thursday, September 12, 2002 2:06 PM\n&gt; To: rest-discuss@yahoogroups.com\n&gt; Subject: [rest-discuss] Rediscovering Web Architecture from first\n&gt; principles\n&gt; \n&gt; \n&gt;     = Addressing =\n&gt; \n&gt; The Web is first and foremost a publishing platform. It is used to\n&gt; publish information and services.\n&gt; \n&gt; We will start with the question of the best way to publish \n&gt; information.\n&gt; There are two basic strategies possible: one is to describe \n&gt; uniquely for\n&gt; each information object how to fetch it. Another is to standardize the\n&gt; fetching mechanism and instead specify only the minimal information\n&gt; required to actually do the fetch: an &quot;address&quot;.\n&gt; \n&gt; The older FTP protocol uses the first model. When you wanted \n&gt; someone to \n&gt; download something through FTP you would give them instructions about \n&gt; how to log into an FTP site, switch to the appropriate \n&gt; directory and get \n&gt; the appropriate file. Conversely, HTTP leaves only one free \n&gt; parameter: \n&gt; the address. Everything else falls out of that. You do not need to \n&gt; choose the method that is used: it is always GET. You do not need to \n&gt; decide what server to issue the command to: the address of the \n&gt; recommended server is embedded in the address (&quot;Uniform Resource \n&gt; identifier&quot;, or &quot;URI&quot;).\n&gt; \n&gt; This leads us to the Web principle that all resources should be\n&gt; identifiable by unique address so that they can be fetched \n&gt; with only GET \n&gt; and the address.\n&gt; \n&gt;     = Uniform Interface =\n&gt; \n&gt; Standardizing the means of information download is important for\n&gt; maximizing the number of applications that can download information\n&gt; without necessarily understanding the semantics of the \n&gt; information they\n&gt; are downloading. Examples include caching and prefetching\n&gt; proxies, command line downloading tools, web browsers, \n&gt; spiders and XSLT\n&gt; engines.\n&gt; \n&gt; Any architecture that has multiple ways of saying &quot;get me some\n&gt; information&quot; will experience interoperability problems that the Web\n&gt; avoids by having a few, globally optimized ways of doing so (basically\n&gt; HTTP and FTP GET methods).\n&gt; \n&gt; Because HTTP&#39;s GET is used by such a wide variety of tools, it is\n&gt; necessary that it have very clear semantics. For instance, a \n&gt; GET cannot\n&gt; be interpreted as signing a user up for a service or a \n&gt; prefetching cache\n&gt; or spider could sign the user up just by doing its job. Therefore the\n&gt; Web says that end-users are not responsible for any side \n&gt; effects of GET.\n&gt;     Services should not use GET in ways that cause side effects.\n&gt; \n&gt; Let me stress a point made earlier: any architecture that allows every\n&gt; end-node to choose its own mechanism for delivering information (SOAP\n&gt; RPC, CORBA, ...) is strictly less powerful and less interoperable than\n&gt; an architecture that has a single, standardized way to deliver\n&gt; information because it means that every potential consumer of\n&gt; information resources must be customized to talk to every publisher of\n&gt; information. This is an interoperability nightmare.\n&gt; \n&gt; The concensus on this point is sufficiently strong that the W3C has\n&gt; extended SOAP 1.2 to support HTTP GET so that it would better take\n&gt; advantage of the features of web architecture.\n&gt; \n&gt;     = Hypermedia =\n&gt; \n&gt; But simply returning named information is not always enough. Often the\n&gt; client application or human web surfer will not know exactly what\n&gt; information they need in advance. Essentially they need to be given a\n&gt; menu of options so that they may choose the appropriate one. For\n&gt; instance a flight-purchasing agent might be presented with a list of\n&gt; flights and might choose the &quot;best&quot; one based on a complex algorithm\n&gt; that depends upon price, flight length and flight time. In \n&gt; this case, we\n&gt; need an information object (a flight list) that refers to other\n&gt; information objects (the flights). A data representation that has\n&gt; references embedded among data is known in Web terminology as \n&gt; &quot;hypermedia&quot;.\n&gt; \n&gt; Listing things is a wonderful way of helping a client navigate to\n&gt; information because they know exactly what is available and sometimes\n&gt; knowing the list is as or more important as having access to any \n&gt; particular item.\n&gt; \n&gt; Google is an example of an application that really does not care about\n&gt; any particular page on your site much, but cares very much about\n&gt; ensuring that it has a relatively complete list of pages. So \n&gt; hypermedia\n&gt; is a very important part of web architecture because it allows\n&gt; discovery. Where possible, information delivered on the Web should be\n&gt; organized into webs of hyperlinked hypermedia documents.\n&gt; \n&gt; Because the Web is basically a flat, global address space (modulo\n&gt; machines behind firewalls etc.), any resource can refer to any other\n&gt; resource, no matter whether they use the same data representation or\n&gt; even the same access protocol (e.g. HTTP versus FTP). This promiscuous\n&gt; connectedness is what makes the Web so great and important!\n&gt; \n&gt; The great thing about using hypermedia as an organizational model for\n&gt; information repositories and services is that one process or \n&gt; individual\n&gt; can direct another process or individual to look at and deal with a\n&gt; particular resource by address and can choose the appropriate \n&gt; amount of\n&gt; context. For instance, you can direct a purchase order processing\n&gt; application to a particular purchase order rather than to a whole\n&gt; &quot;purchase order application&quot;. This is in contrast to dominant web\n&gt; services methodologies that hide many resources behind a \n&gt; single URI and\n&gt; therefore makes addressing those individual resources impossible.\n&gt; Imagine if someone wanted to send you a link to the Wall \n&gt; Street Journal\n&gt; and required you to always go to the front screen!\n&gt; \n&gt;     = Queries =\n&gt; \n&gt; Sometimes the information provider has such a large database of\n&gt; information that it is not practically (or economically) \n&gt; feasible for it\n&gt; to deliver to the requestor in total or even to segment into many\n&gt; hypermedia documents. The requestor needs to specify some reasonable\n&gt; filter. This is a fallback position because it becomes difficult or\n&gt; impossible for the requestor to enumerate all of the information items\n&gt; even if this might be useful or important. Nevertheless, reality\n&gt; requires that sometimes filtering happen on the server side \n&gt; and the Web\n&gt; allows this through HTTP URI &quot;query parameters&quot;.\n&gt; \n&gt; The beautiful part of query parameters is that they are expressed as\n&gt; part of the URI so that all of the tools we&#39;ve built up for \n&gt; downloading\n&gt; ordinary hyperdocument resources and lists of hyperdocument resources\n&gt; can also be used on filtered lists of hyperdocument \n&gt; resources. The only\n&gt; difference is that in this case, the URI is partially \n&gt; constructed by the\n&gt; client application, under instructions from the server, rather than\n&gt; being constructed by the server and being totally opaque to \n&gt; the server.\n&gt; But once the URI is constructed, it is as bonified a URI as any other\n&gt; one and may be put into any slot expecting a URI. They can be\n&gt; &quot;promiscuously connected&quot;, cached, downloaded with command line tools,\n&gt; and so forth.\n&gt; \n&gt;     = Representations =\n&gt; \n&gt; As the Web evolves it becomes increasingly clear that the concepts\n&gt; addressed by URIs and the bits available at those URIs have distinct\n&gt; lifecycles and properties. &quot;www.theonion.com&quot; is a news magazine. I\n&gt; cannot predict what bits you will get if you dereference on \n&gt; the day you\n&gt; read this essay. In order to discuss this distinction, we \n&gt; need words for\n&gt; the thing that is addressed and the bits you get by going there on a\n&gt; particular day, with a particular user agent, etc. The \n&gt; concept is known\n&gt; as a &quot;resource&quot;. The bits are known as a &quot;representation&quot;.\n&gt; \n&gt; Representations have media-types. Resources do not. In-so-far as\n&gt; resources are &quot;typed&quot; (and HTTP has nothing to say about \n&gt; this) you might\n&gt; say that they are typed by RDF. The distinction between representation\n&gt; and resource allows us a very powerful form of extensibility and\n&gt; adaptability. The Web has a feature called content negotiation which\n&gt; allows resource consumers to ask for the resource in a variety of\n&gt; different representations. One representation might be WML \n&gt; optimized for\n&gt; hand-held computers. Another might be XHTML optimized for browsers.\n&gt; Others might be PDF optimized for printers and RDF optimized \n&gt; for machine\n&gt; discovery. As new standards come into existence, they can be served as\n&gt; new representations for the information, enabling evolution of the\n&gt; resource without backwards compatibility problems.\n&gt; \n&gt; This is a good point to emphasize something that has been so-far\n&gt; implicit. There is nothing in the Web architecture which is \n&gt; specific to\n&gt; interactions with a human being at one end and a machine at the other.\n&gt; Existing information resources can be made machine-accessible \n&gt; by adding\n&gt; an XML (or XML/RDF) representation alongside existing HTML\n&gt; representations. Human beings are one kind of client for web \n&gt; resources.\n&gt; Machines are another.\n&gt; \n&gt;     = Services =\n&gt; \n&gt; So far we have described the Web as an information publishing \n&gt; platform.\n&gt; But over the years it has also become the world&#39;s leading service\n&gt; publishing platform. There are services for bidding on \n&gt; auctions, booking \n&gt; flights, generating insults and anything else you might dream of. The\n&gt; biggest distinction between publishing information and publishing a\n&gt; service is that the service may require the service provider \n&gt; and client\n&gt; working together to generate new resources, change existing \n&gt; resources or\n&gt; delete resources. In other words the conversation is two-way \n&gt; rather than\n&gt; one-way.\n&gt; \n&gt; Now before we go into detail on services I want to point out that an\n&gt; important sub-task in publishing almost any service is publishing\n&gt; information either held by or relating to that service. There is a\n&gt; tendency to forget this when developing services using \n&gt; technologies such\n&gt; as SOAP and XML-RPC. For instance a part of a stock purchasing service\n&gt; might include a means to get the stock price. The traditional\n&gt; SOAP/XML-RPC way to do this is to invent a new method called\n&gt; getStockPrice. I have already discussed the interoperability \n&gt; limitations\n&gt; of this model. So the first thing to remember about \n&gt; publishing services\n&gt; is that whatever you do, do not neglect the information \n&gt; publishing part\n&gt; of your service. If it can benefit from the web architecture features\n&gt; described above, use them.\n&gt; \n&gt; The second important thing to remember about publishing \n&gt; services is that\n&gt; publishing information is crucial for the flexibility, reliability and\n&gt; scalability of your service. Let&#39;s deal with each of these in turn.\n&gt; Imagine a service that allows the client and server to work \n&gt; together to\n&gt; generate a purchase order. Now they need to decide what to do with the\n&gt; generated purchase order. One option is that each of them can give the\n&gt; order a unique identifier (e.g. &quot;PO number&quot;) and maintain a local copy\n&gt; of it. This arrangement makes it difficult to bring third parties into\n&gt; the conversation and to utilize URI-aware tools like spiders, caches,\n&gt; inferencers and XSLT transformation engines. It would be \n&gt; better to give\n&gt; the purchase order its own URI. Generally, if there is \n&gt; information that\n&gt; is of interest to both or all participants in a conversation, that\n&gt; information should be given a URI so that new participants \n&gt; can be easily\n&gt; brought in after the fact.\n&gt; \n&gt; Another aspect of flexibility is allowing a variety of different kinds\n&gt; of clients. As long as the purchase order has a URI, the client can\n&gt; decide how stateful or stateless it should be. If it wants to keep a\n&gt; copy of the purchase order it can (more robust and paranoid clients\n&gt; will). But if it wants to let the server manage it, it can merely keep\n&gt; the URI and refresh from the server when it needs \n&gt; information. In a case\n&gt; where the server is allowed to unilaterally change the information\n&gt; resource (i.e. not a purchase order), the client can always get the\n&gt; latest version of the resource using a GET.\n&gt; \n&gt; Emphasizing the information publishing portion of your service is also\n&gt; important for reliability reasons. Continuing with the purchase order\n&gt; example, consider what would happen if the client party \n&gt; missed a message\n&gt; or had its state corrupted during the communication. As long as all\n&gt; relevant information has been exposed on the server as URIs, it could\n&gt; rebuild its state with nothing more than the URI representing the\n&gt; resource. Conversely, in situations where the state of the \n&gt; conversation\n&gt; is implicit, one lost message can throw the client \n&gt; irreconcilably out of\n&gt; sync with the server. Of course if the service consumer somehow loses\n&gt; the URI for the thing it is talking about (e.g. the purchase \n&gt; order URI)\n&gt; then you are in trouble. But even then you can use discovery and query\n&gt; techniques to re-establish contact. For this and other \n&gt; reasons, resource\n&gt; discovery should always be an important part of service design.\n&gt; \n&gt; Finally there is the issue of scalability. It is often the case that\n&gt; once an information resource has been created, a \n&gt; representation of it is\n&gt; retrieved many times. Even a purchase order may be read over and over\n&gt; again by internal and external auditors and order fulfillment systems.\n&gt; Using standard web techniques, these representations can be cached.\n&gt; \n&gt; So far, I&#39;ve tried to show how information publishing is a \n&gt; crucial part\n&gt; of all service publishing projects and thus to show that the service\n&gt; publishing problem is an _extension_ of the information publishing\n&gt; problem, not a different problem altogether. Next we will describe how\n&gt; we can extend the web architecture into service publishing.\n&gt; \n&gt;    = Resource construction and mutation =\n&gt; \n&gt; Consider a service like buying sneakers. There are three \n&gt; reasons that we\n&gt; need to move beyond the GET-based web we have described. \n&gt; First, we will\n&gt; want to create purchase orders, so we need a way to create objects.\n&gt; Second, we need information to flow from the customer to the service\n&gt; provider rather than vice versa. Third, we need to allow the &quot;side\n&gt; effect&quot; of actually shipping the shoes.\n&gt; \n&gt; The HTTP method designed for creating and mutating objects, with\n&gt; possible side effects, is POST. POST is neither more nor less powerful\n&gt; than GET. It is just different. GET&#39;s safety (side-effect-freeness)\n&gt; means that clients have extreme flexibility in structuring \n&gt; applications\n&gt; that rely heavily on GET. In particular, GET allows very &quot;declarative&quot;\n&gt; applications that say what needs to be done but does not provide any\n&gt; instructions on how to do it. For instance if an XSLT stylesheet needs\n&gt; to deal with an XML element inside of a web resource it can retrieve\n&gt; that document once, or ten times, or a hundred times, at its own\n&gt; discretion. It might choose to do it once to optimize for \n&gt; bandwidth or a\n&gt; hundred times to optimize for client-side memory space. If the XSLT is\n&gt; using multiple documents, it can also choose the order that \n&gt; it retreives\n&gt; them at its own discretion.\n&gt; \n&gt; But if you do need side-effects then you need to give up some of GETs\n&gt; advantages. Then you need POST. Because POST invocations may \n&gt; have side \n&gt; effects, you must be very careful about the order in which you invoke \n&gt; POST methods. You need to add the shoes to the shopping cart \n&gt; before you \n&gt; checkout of the online store and not vice versa.\n&gt; \n&gt; POST has another related strength/weakness. The input to GET is very \n&gt; simple: basically just an address. The Web infrastructure strongly \n&gt; encourages you to move retrievable information into an \n&gt; addressable URI. \n&gt; But when the service provider and client are working together \n&gt; to create \n&gt; new resources or modify existing ones, they both need to contribute \n&gt; information. This requires a higher level of coordination which makes \n&gt; POST-based integration more difficult than GET-based integration. But \n&gt; this is the price of solving the more difficult problem of building \n&gt; information resources rather than simply delivering them.\n&gt; \n&gt; POST and GET work together in important ways. Using GET-based \n&gt; navigation \n&gt; you can find the service you want to invoke. It could even report its \n&gt; quality of service characteristics, terms and conditions and \n&gt; so forth. \n&gt; Then you use POST to invoke it. This will usually either mutate or \n&gt; create a resource. This resource has a URI that you can use GET to \n&gt; retrieve whenever you need it. You can also refer third \n&gt; parties at the \n&gt; resource via its URI and they can GET it. There is no need to \n&gt; coordinate \n&gt; who GETs first or how many times you GET because GET is safe \n&gt; and idempotent.\n&gt; \n&gt; POST can handle any operation which changes client-side state in a \n&gt; manner that would be inappropriate for GET. But there are two \n&gt; operations \n&gt; that have pretty clear semantics that can be separated out \n&gt; from the mass \n&gt; of POST-based actions. Sometimes you have a URI and you want to \n&gt; overwrite its content. For instance you load a document into \n&gt; your word \n&gt; processor, make a few changes and want to save it back. Or you are \n&gt; maintaining a stock quote service and it is your job to udpdate the \n&gt; quotes as the most recently quoted price change. PUT allows \n&gt; these. The \n&gt; other operation is DELETE for destroying resources (i.e. making them \n&gt; into 404s).\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; \n&gt; ------------------------ Yahoo! Groups Sponsor \n&gt; ---------------------~--&gt;\n&gt; Plan to Sell a Home?\n&gt; http://us.click.yahoo.com/J2SnNA/y.lEAA/MVfIAA/W6uqlB/TM\n&gt; --------------------------------------------------------------\n&gt; -------~-&gt;\n&gt; \n&gt; To unsubscribe from this group, send an email to:\n&gt; rest-discuss-unsubscribe@yahoogroups.com\n&gt; \n&gt;  \n&gt; \n&gt; Your use of Yahoo! Groups is subject to \nhttp://docs.yahoo.com/info/terms/ \n\n\n"}}